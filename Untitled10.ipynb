{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNotza4gDtPC9nE/2njcbF1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/2403a52012-lgtm/AIAC/blob/main/Untitled10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fen_VFHqVBJx"
      },
      "outputs": [],
      "source": [
        "Tasks:1\n",
        "1. Load train.csv and select features\n",
        "2. Handle missing values and encode categorical features.\n",
        "3. Train an SVM Classifier (SVC) using:\n",
        "Linear kernel\n",
        "RBF kernel\n",
        "4. Compare both kernels using:\n",
        "Accuracy\n",
        "Confusion Matrix\n",
        "Classification Report\n",
        "5. Identify which kernel performs better and justify.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "203b9967",
        "outputId": "ad15903b-cbcd-4e93-8920-7fbeca01648f"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the train.csv file\n",
        "df = pd.read_csv('gender_submission.csv')\n",
        "\n",
        "# Display the first 5 rows of the DataFrame\n",
        "print(\"First 5 rows of the DataFrame:\")\n",
        "print(df.head())\n",
        "\n",
        "# Display the column names and their data types\n",
        "print(\"\\nDataFrame Info:\")\n",
        "df.info()\n",
        "\n",
        "# Based on common practice for Titanic-like datasets, identify the target and potential features\n",
        "# We'll select features that are commonly used and seem relevant, excluding identifiers and potentially high-missing/complex columns like 'Cabin' or 'Name'.\n",
        "target = 'Survived'\n",
        "features = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']\n",
        "\n",
        "print(f\"\\nTarget variable identified: {target}\")\n",
        "print(f\"Initial features selected: {features}\")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First 5 rows of the DataFrame:\n",
            "   PassengerId  Survived\n",
            "0          892         0\n",
            "1          893         1\n",
            "2          894         0\n",
            "3          895         0\n",
            "4          896         1\n",
            "\n",
            "DataFrame Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 418 entries, 0 to 417\n",
            "Data columns (total 2 columns):\n",
            " #   Column       Non-Null Count  Dtype\n",
            "---  ------       --------------  -----\n",
            " 0   PassengerId  418 non-null    int64\n",
            " 1   Survived     418 non-null    int64\n",
            "dtypes: int64(2)\n",
            "memory usage: 6.7 KB\n",
            "\n",
            "Target variable identified: Survived\n",
            "Initial features selected: ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cbb7e245",
        "outputId": "56dab776-aa73-4ce3-a4c4-0ad47a117faa"
      },
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "from io import StringIO\n",
        "\n",
        "# URL for the train.csv file (e.g., from Kaggle's Titanic dataset)\n",
        "url = \"https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv\"\n",
        "\n",
        "try:\n",
        "    # Attempt to download the file directly\n",
        "    response = requests.get(url)\n",
        "    response.raise_for_status() # Raise an exception for HTTP errors (4xx or 5xx)\n",
        "\n",
        "    # Load the train.csv file from the downloaded content\n",
        "    df = pd.read_csv(StringIO(response.text))\n",
        "    print(\"train.csv loaded successfully from URL.\")\n",
        "\n",
        "except requests.exceptions.RequestException as e:\n",
        "    print(f\"Error downloading or loading file from URL: {e}\")\n",
        "    # Fallback if the URL download fails, try local file (though it failed before)\n",
        "    try:\n",
        "        df = pd.read_csv('train.csv')\n",
        "        print(\"train.csv loaded successfully from local file (fallback).\")\n",
        "    except FileNotFoundError:\n",
        "        print(\"train.csv not found locally either. Please ensure the file is in the correct directory or the URL is valid.\")\n",
        "        # Create an empty DataFrame to prevent further errors, or raise a more specific error\n",
        "        df = pd.DataFrame()\n",
        "\n",
        "# Display the first 5 rows of the DataFrame\n",
        "print(\"\\nFirst 5 rows of the DataFrame:\")\n",
        "print(df.head())\n",
        "\n",
        "# Display the column names and their data types\n",
        "print(\"\\nDataFrame Info:\")\n",
        "df.info()\n",
        "\n",
        "# Based on common practice for Titanic-like datasets, identify the target and potential features\n",
        "# We'll select features that are commonly used and seem relevant, excluding identifiers and potentially high-missing/complex columns like 'Cabin' or 'Name'.\n",
        "target = 'Survived'\n",
        "features = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']\n",
        "\n",
        "print(f\"\\nTarget variable identified: {target}\")\n",
        "print(f\"Initial features selected: {features}\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train.csv loaded successfully from URL.\n",
            "\n",
            "First 5 rows of the DataFrame:\n",
            "   PassengerId  Survived  Pclass  \\\n",
            "0            1         0       3   \n",
            "1            2         1       1   \n",
            "2            3         1       3   \n",
            "3            4         1       1   \n",
            "4            5         0       3   \n",
            "\n",
            "                                                Name     Sex   Age  SibSp  \\\n",
            "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
            "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
            "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
            "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
            "4                           Allen, Mr. William Henry    male  35.0      0   \n",
            "\n",
            "   Parch            Ticket     Fare Cabin Embarked  \n",
            "0      0         A/5 21171   7.2500   NaN        S  \n",
            "1      0          PC 17599  71.2833   C85        C  \n",
            "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
            "3      0            113803  53.1000  C123        S  \n",
            "4      0            373450   8.0500   NaN        S  \n",
            "\n",
            "DataFrame Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 891 entries, 0 to 890\n",
            "Data columns (total 12 columns):\n",
            " #   Column       Non-Null Count  Dtype  \n",
            "---  ------       --------------  -----  \n",
            " 0   PassengerId  891 non-null    int64  \n",
            " 1   Survived     891 non-null    int64  \n",
            " 2   Pclass       891 non-null    int64  \n",
            " 3   Name         891 non-null    object \n",
            " 4   Sex          891 non-null    object \n",
            " 5   Age          714 non-null    float64\n",
            " 6   SibSp        891 non-null    int64  \n",
            " 7   Parch        891 non-null    int64  \n",
            " 8   Ticket       891 non-null    object \n",
            " 9   Fare         891 non-null    float64\n",
            " 10  Cabin        204 non-null    object \n",
            " 11  Embarked     889 non-null    object \n",
            "dtypes: float64(2), int64(5), object(5)\n",
            "memory usage: 83.7+ KB\n",
            "\n",
            "Target variable identified: Survived\n",
            "Initial features selected: ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41f74d91",
        "outputId": "0af95ad6-169c-456e-8111-66efe6619192"
      },
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "from io import StringIO\n",
        "\n",
        "# URL for the train.csv file (e.g., from Kaggle's Titanic dataset)\n",
        "url = \"https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv\"\n",
        "\n",
        "try:\n",
        "    # Attempt to download the file directly\n",
        "    response = requests.get(url)\n",
        "    response.raise_for_status() # Raise an exception for HTTP errors (4xx or 5xx)\n",
        "\n",
        "    # Load the train.csv file from the downloaded content\n",
        "    df = pd.read_csv(StringIO(response.text))\n",
        "    print(\"train.csv loaded successfully from URL.\")\n",
        "\n",
        "except requests.exceptions.RequestException as e:\n",
        "    print(f\"Error downloading or loading file from URL: {e}\")\n",
        "    # Fallback if the URL download fails, try local file (though it failed before)\n",
        "    try:\n",
        "        df = pd.read_csv('train.csv')\n",
        "        print(\"train.csv loaded successfully from local file (fallback).\")\n",
        "    except FileNotFoundError:\n",
        "        print(\"train.csv not found locally either. Please ensure the file is in the correct directory or the URL is valid.\")\n",
        "        # Create an empty DataFrame to prevent further errors, or raise a more specific error\n",
        "        df = pd.DataFrame()\n",
        "\n",
        "# Display the first 5 rows of the DataFrame\n",
        "print(\"\\nFirst 5 rows of the DataFrame:\")\n",
        "print(df.head())\n",
        "\n",
        "# Display the column names and their data types\n",
        "print(\"\\nDataFrame Info:\")\n",
        "df.info()\n",
        "\n",
        "# Based on common practice for Titanic-like datasets, identify the target and potential features\n",
        "# We'll select features that are commonly used and seem relevant, excluding identifiers and potentially high-missing/complex columns like 'Cabin' or 'Name'.\n",
        "target = 'Survived'\n",
        "features = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']\n",
        "\n",
        "print(f\"\\nTarget variable identified: {target}\")\n",
        "print(f\"Initial features selected: {features}\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train.csv loaded successfully from URL.\n",
            "\n",
            "First 5 rows of the DataFrame:\n",
            "   PassengerId  Survived  Pclass  \\\n",
            "0            1         0       3   \n",
            "1            2         1       1   \n",
            "2            3         1       3   \n",
            "3            4         1       1   \n",
            "4            5         0       3   \n",
            "\n",
            "                                                Name     Sex   Age  SibSp  \\\n",
            "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
            "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
            "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
            "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
            "4                           Allen, Mr. William Henry    male  35.0      0   \n",
            "\n",
            "   Parch            Ticket     Fare Cabin Embarked  \n",
            "0      0         A/5 21171   7.2500   NaN        S  \n",
            "1      0          PC 17599  71.2833   C85        C  \n",
            "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
            "3      0            113803  53.1000  C123        S  \n",
            "4      0            373450   8.0500   NaN        S  \n",
            "\n",
            "DataFrame Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 891 entries, 0 to 890\n",
            "Data columns (total 12 columns):\n",
            " #   Column       Non-Null Count  Dtype  \n",
            "---  ------       --------------  -----  \n",
            " 0   PassengerId  891 non-null    int64  \n",
            " 1   Survived     891 non-null    int64  \n",
            " 2   Pclass       891 non-null    int64  \n",
            " 3   Name         891 non-null    object \n",
            " 4   Sex          891 non-null    object \n",
            " 5   Age          714 non-null    float64\n",
            " 6   SibSp        891 non-null    int64  \n",
            " 7   Parch        891 non-null    int64  \n",
            " 8   Ticket       891 non-null    object \n",
            " 9   Fare         891 non-null    float64\n",
            " 10  Cabin        204 non-null    object \n",
            " 11  Embarked     889 non-null    object \n",
            "dtypes: float64(2), int64(5), object(5)\n",
            "memory usage: 83.7+ KB\n",
            "\n",
            "Target variable identified: Survived\n",
            "Initial features selected: ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7e9b8398",
        "outputId": "24c2d9c5-b664-478c-8222-ee3cf3ddd026"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Separate features (X) from the target variable (y)\n",
        "X = df[features].copy()\n",
        "y = df[target].copy()\n",
        "\n",
        "print(\"Original features before preprocessing:\")\n",
        "print(X.head())\n",
        "print(\"\\nTarget variable:\")\n",
        "print(y.head())\n",
        "\n",
        "# Handle missing values in 'Age' column by imputing with the mean\n",
        "X['Age'].fillna(X['Age'].mean(), inplace=True)\n",
        "\n",
        "# Handle missing values in 'Embarked' column by imputing with the most frequent value (mode)\n",
        "# .mode()[0] is used because mode() can return multiple values if there's a tie\n",
        "X['Embarked'].fillna(X['Embarked'].mode()[0], inplace=True)\n",
        "\n",
        "print(\"\\nMissing values after imputation:\")\n",
        "print(X.isnull().sum())\n",
        "\n",
        "# Identify categorical features\n",
        "categorical_features = ['Sex', 'Embarked']\n",
        "\n",
        "# Apply one-hot encoding to identified categorical features\n",
        "X = pd.get_dummies(X, columns=categorical_features, drop_first=True, dtype=int)\n",
        "\n",
        "print(\"\\nFeatures after one-hot encoding:\")\n",
        "print(X.head())\n",
        "\n",
        "# Split the preprocessed data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(f\"\\nShape of X_train: {X_train.shape}\")\n",
        "print(f\"Shape of X_test: {X_test.shape}\")\n",
        "print(f\"Shape of y_train: {y_train.shape}\")\n",
        "print(f\"Shape of y_test: {y_test.shape}\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original features before preprocessing:\n",
            "   Pclass     Sex   Age  SibSp  Parch     Fare Embarked\n",
            "0       3    male  22.0      1      0   7.2500        S\n",
            "1       1  female  38.0      1      0  71.2833        C\n",
            "2       3  female  26.0      0      0   7.9250        S\n",
            "3       1  female  35.0      1      0  53.1000        S\n",
            "4       3    male  35.0      0      0   8.0500        S\n",
            "\n",
            "Target variable:\n",
            "0    0\n",
            "1    1\n",
            "2    1\n",
            "3    1\n",
            "4    0\n",
            "Name: Survived, dtype: int64\n",
            "\n",
            "Missing values after imputation:\n",
            "Pclass      0\n",
            "Sex         0\n",
            "Age         0\n",
            "SibSp       0\n",
            "Parch       0\n",
            "Fare        0\n",
            "Embarked    0\n",
            "dtype: int64\n",
            "\n",
            "Features after one-hot encoding:\n",
            "   Pclass   Age  SibSp  Parch     Fare  Sex_male  Embarked_Q  Embarked_S\n",
            "0       3  22.0      1      0   7.2500         1           0           1\n",
            "1       1  38.0      1      0  71.2833         0           0           0\n",
            "2       3  26.0      0      0   7.9250         0           0           1\n",
            "3       1  35.0      1      0  53.1000         0           0           1\n",
            "4       3  35.0      0      0   8.0500         1           0           1\n",
            "\n",
            "Shape of X_train: (712, 8)\n",
            "Shape of X_test: (179, 8)\n",
            "Shape of y_train: (712,)\n",
            "Shape of y_test: (179,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3929455305.py:13: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  X['Age'].fillna(X['Age'].mean(), inplace=True)\n",
            "/tmp/ipython-input-3929455305.py:17: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  X['Embarked'].fillna(X['Embarked'].mode()[0], inplace=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "78415100",
        "outputId": "9d02f19d-5a52-4182-9bf0-bb7e9ad72dc6"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Separate features (X) from the target variable (y)\n",
        "X = df[features].copy()\n",
        "y = df[target].copy()\n",
        "\n",
        "print(\"Original features before preprocessing:\")\n",
        "print(X.head())\n",
        "print(\"\\nTarget variable:\")\n",
        "print(y.head())\n",
        "\n",
        "# Handle missing values in 'Age' column by imputing with the mean\n",
        "X['Age'] = X['Age'].fillna(X['Age'].mean())\n",
        "\n",
        "# Handle missing values in 'Embarked' column by imputing with the most frequent value (mode)\n",
        "# .mode()[0] is used because mode() can return multiple values if there's a tie\n",
        "X['Embarked'] = X['Embarked'].fillna(X['Embarked'].mode()[0])\n",
        "\n",
        "print(\"\\nMissing values after imputation:\")\n",
        "print(X.isnull().sum())\n",
        "\n",
        "# Identify categorical features\n",
        "categorical_features = ['Sex', 'Embarked']\n",
        "\n",
        "# Apply one-hot encoding to identified categorical features\n",
        "X = pd.get_dummies(X, columns=categorical_features, drop_first=True, dtype=int)\n",
        "\n",
        "print(\"\\nFeatures after one-hot encoding:\")\n",
        "print(X.head())\n",
        "\n",
        "# Split the preprocessed data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(f\"\\nShape of X_train: {X_train.shape}\")\n",
        "print(f\"Shape of X_test: {X_test.shape}\")\n",
        "print(f\"Shape of y_train: {y_train.shape}\")\n",
        "print(f\"Shape of y_test: {y_test.shape}\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original features before preprocessing:\n",
            "   Pclass     Sex   Age  SibSp  Parch     Fare Embarked\n",
            "0       3    male  22.0      1      0   7.2500        S\n",
            "1       1  female  38.0      1      0  71.2833        C\n",
            "2       3  female  26.0      0      0   7.9250        S\n",
            "3       1  female  35.0      1      0  53.1000        S\n",
            "4       3    male  35.0      0      0   8.0500        S\n",
            "\n",
            "Target variable:\n",
            "0    0\n",
            "1    1\n",
            "2    1\n",
            "3    1\n",
            "4    0\n",
            "Name: Survived, dtype: int64\n",
            "\n",
            "Missing values after imputation:\n",
            "Pclass      0\n",
            "Sex         0\n",
            "Age         0\n",
            "SibSp       0\n",
            "Parch       0\n",
            "Fare        0\n",
            "Embarked    0\n",
            "dtype: int64\n",
            "\n",
            "Features after one-hot encoding:\n",
            "   Pclass   Age  SibSp  Parch     Fare  Sex_male  Embarked_Q  Embarked_S\n",
            "0       3  22.0      1      0   7.2500         1           0           1\n",
            "1       1  38.0      1      0  71.2833         0           0           0\n",
            "2       3  26.0      0      0   7.9250         0           0           1\n",
            "3       1  35.0      1      0  53.1000         0           0           1\n",
            "4       3  35.0      0      0   8.0500         1           0           1\n",
            "\n",
            "Shape of X_train: (712, 8)\n",
            "Shape of X_test: (179, 8)\n",
            "Shape of y_train: (712,)\n",
            "Shape of y_test: (179,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f70749ce",
        "outputId": "d5969bf9-eac9-4f6c-f4f3-33153392b18a"
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "# Initialize and train the SVM Classifier with a linear kernel\n",
        "svc_linear = SVC(kernel='linear', random_state=42)\n",
        "svc_linear.fit(X_train, y_train)\n",
        "print(\"SVC with linear kernel trained successfully.\")\n",
        "\n",
        "# Initialize and train the SVM Classifier with an RBF kernel\n",
        "svc_rbf = SVC(kernel='rbf', random_state=42)\n",
        "svc_rbf.fit(X_train, y_train)\n",
        "print(\"SVC with RBF kernel trained successfully.\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVC with linear kernel trained successfully.\n",
            "SVC with RBF kernel trained successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a5fbc838",
        "outputId": "ec812ce8-5695-4735-c82a-744600f26310"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "# --- Evaluate Linear Kernel SVM ---\n",
        "print(\"\\n--- Linear Kernel SVM Evaluation ---\")\n",
        "# Make predictions on the test set\n",
        "y_pred_linear = svc_linear.predict(X_test)\n",
        "\n",
        "# Calculate and print Accuracy\n",
        "accuracy_linear = accuracy_score(y_test, y_pred_linear)\n",
        "print(f\"Accuracy (Linear Kernel): {accuracy_linear:.4f}\")\n",
        "\n",
        "# Generate and print Confusion Matrix\n",
        "conf_matrix_linear = confusion_matrix(y_test, y_pred_linear)\n",
        "print(\"\\nConfusion Matrix (Linear Kernel):\\n\", conf_matrix_linear)\n",
        "\n",
        "# Generate and print Classification Report\n",
        "class_report_linear = classification_report(y_test, y_pred_linear)\n",
        "print(\"\\nClassification Report (Linear Kernel):\\n\", class_report_linear)\n",
        "\n",
        "# --- Evaluate RBF Kernel SVM ---\n",
        "print(\"\\n--- RBF Kernel SVM Evaluation ---\")\n",
        "# Make predictions on the test set\n",
        "y_pred_rbf = svc_rbf.predict(X_test)\n",
        "\n",
        "# Calculate and print Accuracy\n",
        "accuracy_rbf = accuracy_score(y_test, y_pred_rbf)\n",
        "print(f\"Accuracy (RBF Kernel): {accuracy_rbf:.4f}\")\n",
        "\n",
        "# Generate and print Confusion Matrix\n",
        "conf_matrix_rbf = confusion_matrix(y_test, y_pred_rbf)\n",
        "print(\"\\nConfusion Matrix (RBF Kernel):\\n\", conf_matrix_rbf)\n",
        "\n",
        "# Generate and print Classification Report\n",
        "class_report_rbf = classification_report(y_test, y_pred_rbf)\n",
        "print(\"\\nClassification Report (RBF Kernel):\\n\", class_report_rbf)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Linear Kernel SVM Evaluation ---\n",
            "Accuracy (Linear Kernel): 0.7821\n",
            "\n",
            "Confusion Matrix (Linear Kernel):\n",
            " [[88 17]\n",
            " [22 52]]\n",
            "\n",
            "Classification Report (Linear Kernel):\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.84      0.82       105\n",
            "           1       0.75      0.70      0.73        74\n",
            "\n",
            "    accuracy                           0.78       179\n",
            "   macro avg       0.78      0.77      0.77       179\n",
            "weighted avg       0.78      0.78      0.78       179\n",
            "\n",
            "\n",
            "--- RBF Kernel SVM Evaluation ---\n",
            "Accuracy (RBF Kernel): 0.6592\n",
            "\n",
            "Confusion Matrix (RBF Kernel):\n",
            " [[99  6]\n",
            " [55 19]]\n",
            "\n",
            "Classification Report (RBF Kernel):\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.64      0.94      0.76       105\n",
            "           1       0.76      0.26      0.38        74\n",
            "\n",
            "    accuracy                           0.66       179\n",
            "   macro avg       0.70      0.60      0.57       179\n",
            "weighted avg       0.69      0.66      0.61       179\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6cde8062",
        "outputId": "c01d1d1a-6d76-49de-d860-ab05a6dacd52"
      },
      "source": [
        "print(\"\\n--- Kernel Performance Comparison and Justification ---\")\n",
        "\n",
        "print(f\"Accuracy for Linear Kernel: {accuracy_linear:.4f}\")\n",
        "print(f\"Accuracy for RBF Kernel: {accuracy_rbf:.4f}\")\n",
        "\n",
        "# Compare accuracies\n",
        "if accuracy_linear > accuracy_rbf:\n",
        "    better_kernel = 'Linear'\n",
        "    worse_kernel = 'RBF'\n",
        "else:\n",
        "    better_kernel = 'RBF'\n",
        "    worse_kernel = 'Linear'\n",
        "\n",
        "print(f\"\\nBased on accuracy, the {better_kernel} kernel performed better.\")\n",
        "\n",
        "print(\"\\n--- Detailed Analysis ---\")\n",
        "\n",
        "print(\"\\nLinear Kernel:\")\n",
        "print(f\"Confusion Matrix:\\n{conf_matrix_linear}\")\n",
        "print(f\"Classification Report:\\n{class_report_linear}\")\n",
        "\n",
        "print(\"\\nRBF Kernel:\")\n",
        "print(f\"Confusion Matrix:\\n{conf_matrix_rbf}\")\n",
        "print(f\"Classification Report:\\n{class_report_rbf}\")\n",
        "\n",
        "print(\"\\n--- Justification ---\")\n",
        "print(\"The Linear Kernel achieved an accuracy of {:.4f}, which is higher than the RBF Kernel's accuracy of {:.4f}.\\\n",
        "\\nLooking at the classification reports:\\n- The Linear Kernel shows a good balance between precision and recall for both classes (0 and 1). For class 0 (not survived), it has a precision of 0.80 and recall of 0.84. For class 1 (survived), it has a precision of 0.75 and recall of 0.70. This suggests it correctly identifies both classes reasonably well.\\n- The RBF Kernel, while having a high recall for class 0 (0.94), significantly struggles with identifying class 1 (survived), as indicated by its low recall of 0.26 and f1-score of 0.38 for class 1. This means it misses a large number of actual survivors.\\n\\nIn terms of correctly classifying positive instances (Survived=1), the Linear Kernel has a higher recall (0.70 vs 0.26) and f1-score (0.73 vs 0.38), indicating it is much better at predicting survival. Although the RBF kernel has higher precision for class 1 (0.76 vs 0.75), its very low recall makes it less effective overall for this class.\")\n",
        "\n",
        "print(f\"\\nTherefore, based on overall accuracy and a more balanced performance across both classes, particularly in identifying positive cases (survivors), the {better_kernel} kernel performs better for this specific dataset and problem.\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Kernel Performance Comparison and Justification ---\n",
            "Accuracy for Linear Kernel: 0.7821\n",
            "Accuracy for RBF Kernel: 0.6592\n",
            "\n",
            "Based on accuracy, the Linear kernel performed better.\n",
            "\n",
            "--- Detailed Analysis ---\n",
            "\n",
            "Linear Kernel:\n",
            "Confusion Matrix:\n",
            "[[88 17]\n",
            " [22 52]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.84      0.82       105\n",
            "           1       0.75      0.70      0.73        74\n",
            "\n",
            "    accuracy                           0.78       179\n",
            "   macro avg       0.78      0.77      0.77       179\n",
            "weighted avg       0.78      0.78      0.78       179\n",
            "\n",
            "\n",
            "RBF Kernel:\n",
            "Confusion Matrix:\n",
            "[[99  6]\n",
            " [55 19]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.64      0.94      0.76       105\n",
            "           1       0.76      0.26      0.38        74\n",
            "\n",
            "    accuracy                           0.66       179\n",
            "   macro avg       0.70      0.60      0.57       179\n",
            "weighted avg       0.69      0.66      0.61       179\n",
            "\n",
            "\n",
            "--- Justification ---\n",
            "The Linear Kernel achieved an accuracy of {:.4f}, which is higher than the RBF Kernel's accuracy of {:.4f}.\n",
            "Looking at the classification reports:\n",
            "- The Linear Kernel shows a good balance between precision and recall for both classes (0 and 1). For class 0 (not survived), it has a precision of 0.80 and recall of 0.84. For class 1 (survived), it has a precision of 0.75 and recall of 0.70. This suggests it correctly identifies both classes reasonably well.\n",
            "- The RBF Kernel, while having a high recall for class 0 (0.94), significantly struggles with identifying class 1 (survived), as indicated by its low recall of 0.26 and f1-score of 0.38 for class 1. This means it misses a large number of actual survivors.\n",
            "\n",
            "In terms of correctly classifying positive instances (Survived=1), the Linear Kernel has a higher recall (0.70 vs 0.26) and f1-score (0.73 vs 0.38), indicating it is much better at predicting survival. Although the RBF kernel has higher precision for class 1 (0.76 vs 0.75), its very low recall makes it less effective overall for this class.\n",
            "\n",
            "Therefore, based on overall accuracy and a more balanced performance across both classes, particularly in identifying positive cases (survivors), the Linear kernel performs better for this specific dataset and problem.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Tasks:\n",
        "1. Load dataset and encode target (M / B).\n",
        "2. Apply StandardScaler for feature scaling.\n",
        "3. Train SVM (SVC) with different C values:\n",
        "C = 0.1, 1, 10\n",
        "4. Evaluate each model using:\n",
        "Accuracy\n",
        "Precision, Recall, F1-score\n",
        "5. Plot confusion matrix for the best model.\n"
      ],
      "metadata": {
        "id": "a0pSNXhvYBYW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "99e217c0",
        "outputId": "05bb5d9e-7683-4e32-947d-2c8d0032771c"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Instantiate StandardScaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit on training data and transform training data\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "\n",
        "# Transform test data using the fitted scaler\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "print(\"Features scaled successfully using StandardScaler.\")\n",
        "print(f\"Shape of X_train_scaled: {X_train_scaled.shape}\")\n",
        "print(f\"Shape of X_test_scaled: {X_test_scaled.shape}\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Features scaled successfully using StandardScaler.\n",
            "Shape of X_train_scaled: (712, 8)\n",
            "Shape of X_test_scaled: (179, 8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "271dafee",
        "outputId": "4c6c3a2f-c406-4541-82ce-21a4856df6cd"
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Define a list of C values to iterate through\n",
        "c_values = [0.1, 1, 10]\n",
        "\n",
        "# Dictionary to store results for each C value\n",
        "svm_results = {}\n",
        "\n",
        "for c in c_values:\n",
        "    print(f\"\\n--- Training SVM with C = {c} ---\")\n",
        "    # Instantiate an SVC classifier with the current C value and a random_state\n",
        "    svc_model = SVC(kernel='rbf', C=c, random_state=42) # Using rbf kernel as it's common for general classification\n",
        "\n",
        "    # Train the SVC model using the scaled training data\n",
        "    svc_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "    # Make predictions on the scaled test data\n",
        "    y_pred = svc_model.predict(X_test_scaled)\n",
        "\n",
        "    # Calculate Accuracy\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    print(f\"Accuracy (C={c}): {accuracy:.4f}\")\n",
        "\n",
        "    # Generate Classification Report\n",
        "    class_report = classification_report(y_test, y_pred, output_dict=True)\n",
        "    print(f\"Classification Report (C={c}):\\n\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "\n",
        "    # Store the calculated metrics for each C value\n",
        "    svm_results[f'C={c}'] = {\n",
        "        'accuracy': accuracy,\n",
        "        'precision_0': class_report['0']['precision'],\n",
        "        'recall_0': class_report['0']['recall'],\n",
        "        'f1_score_0': class_report['0']['f1-score'],\n",
        "        'precision_1': class_report['1']['precision'],\n",
        "        'recall_1': class_report['1']['recall'],\n",
        "        'f1_score_1': class_report['1']['f1-score'],\n",
        "        'model': svc_model\n",
        "    }\n",
        "\n",
        "print(\"\\nSVM models trained and evaluated for all C values.\")\n",
        "# Display overall results summary\n",
        "print(\"\\n--- SVM Results Summary ---\")\n",
        "for c_val, metrics in svm_results.items():\n",
        "    print(f\"{c_val}: Accuracy = {metrics['accuracy']:.4f}, F1-score (class 1) = {metrics['f1_score_1']:.4f}\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Training SVM with C = 0.1 ---\n",
            "Accuracy (C=0.1): 0.8101\n",
            "Classification Report (C=0.1):\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.88      0.84       105\n",
            "           1       0.80      0.72      0.76        74\n",
            "\n",
            "    accuracy                           0.81       179\n",
            "   macro avg       0.81      0.80      0.80       179\n",
            "weighted avg       0.81      0.81      0.81       179\n",
            "\n",
            "\n",
            "--- Training SVM with C = 1 ---\n",
            "Accuracy (C=1): 0.8212\n",
            "Classification Report (C=1):\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.90      0.86       105\n",
            "           1       0.84      0.70      0.76        74\n",
            "\n",
            "    accuracy                           0.82       179\n",
            "   macro avg       0.83      0.80      0.81       179\n",
            "weighted avg       0.82      0.82      0.82       179\n",
            "\n",
            "\n",
            "--- Training SVM with C = 10 ---\n",
            "Accuracy (C=10): 0.8101\n",
            "Classification Report (C=10):\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.90      0.85       105\n",
            "           1       0.82      0.69      0.75        74\n",
            "\n",
            "    accuracy                           0.81       179\n",
            "   macro avg       0.81      0.79      0.80       179\n",
            "weighted avg       0.81      0.81      0.81       179\n",
            "\n",
            "\n",
            "SVM models trained and evaluated for all C values.\n",
            "\n",
            "--- SVM Results Summary ---\n",
            "C=0.1: Accuracy = 0.8101, F1-score (class 1) = 0.7571\n",
            "C=1: Accuracy = 0.8212, F1-score (class 1) = 0.7647\n",
            "C=10: Accuracy = 0.8101, F1-score (class 1) = 0.7500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "3d565017",
        "outputId": "7b9df3b2-fab3-4078-c2e5-e664f30c231e"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "\n",
        "# Identify the best performing model based on accuracy (or F1-score for class 1)\n",
        "# From the summary: C=1 has the highest accuracy and F1-score for class 1\n",
        "best_c_key = 'C=1'\n",
        "best_model_results = svm_results[best_c_key]\n",
        "best_svc_model = best_model_results['model']\n",
        "\n",
        "print(f\"Plotting Confusion Matrix for the best model (C={best_c_key.split('=')[1]})\")\n",
        "\n",
        "# Make predictions with the best model\n",
        "y_pred_best = best_svc_model.predict(X_test_scaled)\n",
        "\n",
        "# Plot the confusion matrix\n",
        "fig, ax = plt.subplots(figsize=(6, 6))\n",
        "disp = ConfusionMatrixDisplay.from_estimator(\n",
        "    best_svc_model, X_test_scaled, y_test, cmap=plt.cm.Blues, ax=ax\n",
        ")\n",
        "disp.ax_.set_title(f'Confusion Matrix for SVM (Best Model: {best_c_key})')\n",
        "plt.show()\n",
        "\n",
        "print(\"Confusion matrix for the best model plotted successfully.\")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plotting Confusion Matrix for the best model (C=1)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion matrix for the best model plotted successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Tasks:3\n",
        "1. Load dataset and preprocess features (handle missing values if any).\n",
        "2. Train SVM classifier using:\n",
        "Polynomial kernel (degree = 2 or 3)\n",
        "RBF kernel\n",
        "3. Use train/test split (80/20) and compare:\n",
        "Accuracy\n",
        "F1-score\n",
        "4. Perform hyperparameter tuning using GridSearchCV for:\n",
        "C and gamma\n",
        "5. Report best parameters and best accuracy.\n"
      ],
      "metadata": {
        "id": "pW7z4K2ZY4sM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bhmu5EstZIRU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61068716",
        "outputId": "4e235062-52e3-42af-d103-a764d4cace4a"
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Define the parameter grid for the Polynomial kernel\n",
        "param_grid_poly = {\n",
        "    'C': [0.1, 1, 10],\n",
        "    'degree': [2, 3],\n",
        "    'kernel': ['poly']\n",
        "}\n",
        "\n",
        "# Initialize GridSearchCV\n",
        "# We set refit='accuracy' to ensure the best estimator is refit on the entire dataset using the highest accuracy score\n",
        "# We set cv=5 for 5-fold cross-validation\n",
        "grid_search_poly = GridSearchCV(SVC(random_state=42), param_grid_poly, scoring=['accuracy', 'f1'], refit='accuracy', cv=5, verbose=2)\n",
        "\n",
        "# Fit GridSearchCV to the scaled training data\n",
        "grid_search_poly.fit(X_train_scaled, y_train)\n",
        "\n",
        "print(\"GridSearchCV for Polynomial kernel completed.\")\n",
        "\n",
        "# Print the best parameters found\n",
        "print(\"\\nBest parameters for Polynomial kernel:\", grid_search_poly.best_params_)\n",
        "\n",
        "# Print the best cross-validation accuracy score\n",
        "print(\"Best cross-validation accuracy for Polynomial kernel:\", grid_search_poly.best_score_)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
            "[CV] END .......................C=0.1, degree=2, kernel=poly; total time=   0.0s\n",
            "[CV] END .......................C=0.1, degree=2, kernel=poly; total time=   0.0s\n",
            "[CV] END .......................C=0.1, degree=2, kernel=poly; total time=   0.0s\n",
            "[CV] END .......................C=0.1, degree=2, kernel=poly; total time=   0.1s\n",
            "[CV] END .......................C=0.1, degree=2, kernel=poly; total time=   0.0s\n",
            "[CV] END .......................C=0.1, degree=3, kernel=poly; total time=   0.0s\n",
            "[CV] END .......................C=0.1, degree=3, kernel=poly; total time=   0.0s\n",
            "[CV] END .......................C=0.1, degree=3, kernel=poly; total time=   0.0s\n",
            "[CV] END .......................C=0.1, degree=3, kernel=poly; total time=   0.0s\n",
            "[CV] END .......................C=0.1, degree=3, kernel=poly; total time=   0.0s\n",
            "[CV] END .........................C=1, degree=2, kernel=poly; total time=   0.0s\n",
            "[CV] END .........................C=1, degree=2, kernel=poly; total time=   0.0s\n",
            "[CV] END .........................C=1, degree=2, kernel=poly; total time=   0.0s\n",
            "[CV] END .........................C=1, degree=2, kernel=poly; total time=   0.0s\n",
            "[CV] END .........................C=1, degree=2, kernel=poly; total time=   0.0s\n",
            "[CV] END .........................C=1, degree=3, kernel=poly; total time=   0.0s\n",
            "[CV] END .........................C=1, degree=3, kernel=poly; total time=   0.0s\n",
            "[CV] END .........................C=1, degree=3, kernel=poly; total time=   0.0s\n",
            "[CV] END .........................C=1, degree=3, kernel=poly; total time=   0.0s\n",
            "[CV] END .........................C=1, degree=3, kernel=poly; total time=   0.0s\n",
            "[CV] END ........................C=10, degree=2, kernel=poly; total time=   0.1s\n",
            "[CV] END ........................C=10, degree=2, kernel=poly; total time=   0.0s\n",
            "[CV] END ........................C=10, degree=2, kernel=poly; total time=   0.0s\n",
            "[CV] END ........................C=10, degree=2, kernel=poly; total time=   0.0s\n",
            "[CV] END ........................C=10, degree=2, kernel=poly; total time=   0.0s\n",
            "[CV] END ........................C=10, degree=3, kernel=poly; total time=   0.1s\n",
            "[CV] END ........................C=10, degree=3, kernel=poly; total time=   0.1s\n",
            "[CV] END ........................C=10, degree=3, kernel=poly; total time=   0.1s\n",
            "[CV] END ........................C=10, degree=3, kernel=poly; total time=   0.1s\n",
            "[CV] END ........................C=10, degree=3, kernel=poly; total time=   0.0s\n",
            "GridSearchCV for Polynomial kernel completed.\n",
            "\n",
            "Best parameters for Polynomial kernel: {'C': 1, 'degree': 3, 'kernel': 'poly'}\n",
            "Best cross-validation accuracy for Polynomial kernel: 0.8272431793558553\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f42af8c4",
        "outputId": "65650767-3ac9-4843-a728-ae24a695c785"
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Define the parameter grid for the RBF kernel\n",
        "param_grid_rbf = {\n",
        "    'C': [0.1, 1, 10],\n",
        "    'gamma': [0.001, 0.01, 0.1, 1],\n",
        "    'kernel': ['rbf']\n",
        "}\n",
        "\n",
        "# Initialize GridSearchCV for RBF kernel\n",
        "grid_search_rbf = GridSearchCV(SVC(random_state=42), param_grid_rbf, scoring=['accuracy', 'f1'], refit='accuracy', cv=5, verbose=2)\n",
        "\n",
        "# Fit GridSearchCV to the scaled training data\n",
        "grid_search_rbf.fit(X_train_scaled, y_train)\n",
        "\n",
        "print(\"GridSearchCV for RBF kernel completed.\")\n",
        "\n",
        "# Print the best parameters found\n",
        "print(\"\\nBest parameters for RBF kernel:\", grid_search_rbf.best_params_)\n",
        "\n",
        "# Print the best cross-validation accuracy score\n",
        "print(\"Best cross-validation accuracy for RBF kernel:\", grid_search_rbf.best_score_)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
            "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
            "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
            "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
            "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
            "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
            "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=   0.1s\n",
            "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
            "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
            "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
            "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=   0.1s\n",
            "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=   0.1s\n",
            "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
            "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
            "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
            "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
            "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=   0.0s\n",
            "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=   0.0s\n",
            "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=   0.1s\n",
            "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=   0.0s\n",
            "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=   0.1s\n",
            "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   0.1s\n",
            "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   0.1s\n",
            "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   0.1s\n",
            "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
            "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
            "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
            "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   0.1s\n",
            "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
            "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
            "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
            "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
            "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
            "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
            "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
            "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
            "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time=   0.0s\n",
            "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time=   0.0s\n",
            "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time=   0.0s\n",
            "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time=   0.0s\n",
            "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time=   0.0s\n",
            "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   0.0s\n",
            "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   0.0s\n",
            "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   0.0s\n",
            "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   0.0s\n",
            "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   0.0s\n",
            "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   0.1s\n",
            "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   0.1s\n",
            "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   0.0s\n",
            "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   0.0s\n",
            "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   0.0s\n",
            "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=   0.1s\n",
            "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=   0.0s\n",
            "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=   0.0s\n",
            "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=   0.0s\n",
            "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=   0.0s\n",
            "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time=   0.0s\n",
            "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time=   0.0s\n",
            "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time=   0.0s\n",
            "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time=   0.0s\n",
            "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time=   0.0s\n",
            "GridSearchCV for RBF kernel completed.\n",
            "\n",
            "Best parameters for RBF kernel: {'C': 10, 'gamma': 0.1, 'kernel': 'rbf'}\n",
            "Best cross-validation accuracy for RBF kernel: 0.8244262779474048\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ce23f75f",
        "outputId": "bcfc454f-0058-442a-99e0-2cdb34980a8d"
      },
      "source": [
        "print(\"\\n--- Best Results for Polynomial Kernel ---\")\n",
        "print(\"Best parameters:\", grid_search_poly.best_params_)\n",
        "print(\"Best cross-validation accuracy:\", grid_search_poly.best_score_)\n",
        "\n",
        "print(\"\\n--- Best Results for RBF Kernel ---\")\n",
        "print(\"Best parameters:\", grid_search_rbf.best_params_)\n",
        "print(\"Best cross-validation accuracy:\", grid_search_rbf.best_score_)\n",
        "\n",
        "print(\"\\n--- Overall Kernel Performance Comparison ---\")\n",
        "\n",
        "if grid_search_poly.best_score_ > grid_search_rbf.best_score_:\n",
        "    overall_best_kernel = \"Polynomial\"\n",
        "    overall_best_score = grid_search_poly.best_score_\n",
        "    second_best_kernel = \"RBF\"\n",
        "    second_best_score = grid_search_rbf.best_score_\n",
        "else:\n",
        "    overall_best_kernel = \"RBF\"\n",
        "    overall_best_score = grid_search_rbf.best_score_\n",
        "    second_best_kernel = \"Polynomial\"\n",
        "    second_best_score = grid_search_poly.best_score_\n",
        "\n",
        "print(f\"The {overall_best_kernel} kernel performed better with a cross-validation accuracy of {overall_best_score:.4f}.\")\n",
        "print(f\"The {second_best_kernel} kernel achieved a cross-validation accuracy of {second_best_score:.4f}.\")\n",
        "\n",
        "print(\"\\n--- Justification ---\")\n",
        "print(f\"The {overall_best_kernel} kernel, with its best parameters ({grid_search_poly.best_params_ if overall_best_kernel == 'Polynomial' else grid_search_rbf.best_params_}), achieved a higher cross-validation accuracy during GridSearchCV. This indicates that it generalized better to unseen data during the cross-validation process compared to the {second_best_kernel} kernel. While both kernels were evaluated on both accuracy and F1-score (due to `scoring=['accuracy', 'f1']`), the `refit='accuracy'` setting means that the 'best' model is chosen based on the highest accuracy. Thus, the kernel with the superior accuracy score is considered the overall best performer in this scenario.\")\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Best Results for Polynomial Kernel ---\n",
            "Best parameters: {'C': 1, 'degree': 3, 'kernel': 'poly'}\n",
            "Best cross-validation accuracy: 0.8272431793558553\n",
            "\n",
            "--- Best Results for RBF Kernel ---\n",
            "Best parameters: {'C': 10, 'gamma': 0.1, 'kernel': 'rbf'}\n",
            "Best cross-validation accuracy: 0.8244262779474048\n",
            "\n",
            "--- Overall Kernel Performance Comparison ---\n",
            "The Polynomial kernel performed better with a cross-validation accuracy of 0.8272.\n",
            "The RBF kernel achieved a cross-validation accuracy of 0.8244.\n",
            "\n",
            "--- Justification ---\n",
            "The Polynomial kernel, with its best parameters ({'C': 1, 'degree': 3, 'kernel': 'poly'}), achieved a higher cross-validation accuracy during GridSearchCV. This indicates that it generalized better to unseen data during the cross-validation process compared to the RBF kernel. While both kernels were evaluated on both accuracy and F1-score (due to `scoring=['accuracy', 'f1']`), the `refit='accuracy'` setting means that the 'best' model is chosen based on the highest accuracy. Thus, the kernel with the superior accuracy score is considered the overall best performer in this scenario.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Tasks:4\n",
        "1. Load train.csv and select numeric features like:\n",
        "2. Handle missing values and scale features.\n",
        "3. Train SVR using:\n",
        "Linear kernel\n",
        "RBF kernel\n",
        "4. Evaluate using:\n",
        "MSE\n",
        "RMSE\n",
        "R score\n",
        "5. Compare SVR vs Linear Regression performance.\n"
      ],
      "metadata": {
        "id": "Z_HOtXJaaYm0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DmruLAnZafIf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ccbedaa1",
        "outputId": "d246ca9c-3686-4eb8-a0f2-be978ed57ba7"
      },
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "from io import StringIO\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# URL for the train.csv file (e.g., from Kaggle's Titanic dataset)\n",
        "url = \"https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv\"\n",
        "\n",
        "try:\n",
        "    # Attempt to download the file directly\n",
        "    response = requests.get(url)\n",
        "    response.raise_for_status() # Raise an exception for HTTP errors (4xx or 5xx)\n",
        "\n",
        "    # Load the train.csv file from the downloaded content\n",
        "    df_reg = pd.read_csv(StringIO(response.text))\n",
        "    print(\"train.csv loaded successfully from URL for regression task.\")\n",
        "\n",
        "except requests.exceptions.RequestException as e:\n",
        "    print(f\"Error downloading or loading file from URL: {e}\")\n",
        "    # Fallback if the URL download fails, try local file\n",
        "    try:\n",
        "        df_reg = pd.read_csv('train.csv')\n",
        "        print(\"train.csv loaded successfully from local file (fallback) for regression task.\")\n",
        "    except FileNotFoundError:\n",
        "        print(\"train.csv not found locally either. Please ensure the file is in the correct directory or the URL is valid.\")\n",
        "        df_reg = pd.DataFrame() # Create an empty DataFrame to prevent further errors\n",
        "\n",
        "# Define the target variable 'y_reg' as 'Fare'\n",
        "y_reg = df_reg['Fare'].copy()\n",
        "\n",
        "# Define the features for regression 'X_reg'\n",
        "features_reg = ['Pclass', 'Age', 'SibSp', 'Parch', 'Sex', 'Embarked']\n",
        "X_reg = df_reg[features_reg].copy()\n",
        "\n",
        "print(\"\\nOriginal features before preprocessing for regression:\")\n",
        "print(X_reg.head())\n",
        "print(\"\\nTarget variable for regression:\")\n",
        "print(y_reg.head())\n",
        "\n",
        "# Handle missing values in 'Age' column by imputing with the mean\n",
        "X_reg['Age'] = X_reg['Age'].fillna(X_reg['Age'].mean())\n",
        "\n",
        "# Handle missing values in 'Embarked' column by imputing with the most frequent value (mode)\n",
        "X_reg['Embarked'] = X_reg['Embarked'].fillna(X_reg['Embarked'].mode()[0])\n",
        "\n",
        "# Handle missing values in 'Fare' column (target variable) by imputing with the mean\n",
        "y_reg = y_reg.fillna(y_reg.mean())\n",
        "\n",
        "print(\"\\nMissing values in features after imputation for regression:\")\n",
        "print(X_reg.isnull().sum())\n",
        "print(\"Missing values in target after imputation for regression:\")\n",
        "print(y_reg.isnull().sum())\n",
        "\n",
        "# Identify categorical features for one-hot encoding\n",
        "categorical_features_reg = ['Sex', 'Embarked']\n",
        "\n",
        "# Apply one-hot encoding to identified categorical features\n",
        "X_reg = pd.get_dummies(X_reg, columns=categorical_features_reg, drop_first=True, dtype=int)\n",
        "\n",
        "print(\"\\nFeatures after one-hot encoding for regression:\")\n",
        "print(X_reg.head())\n",
        "\n",
        "# Split the preprocessed data into training and testing sets for regression\n",
        "X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(X_reg, y_reg, test_size=0.2, random_state=42)\n",
        "\n",
        "print(f\"\\nShape of X_train_reg: {X_train_reg.shape}\")\n",
        "print(f\"Shape of X_test_reg: {X_test_reg.shape}\")\n",
        "print(f\"Shape of y_train_reg: {y_train_reg.shape}\")\n",
        "print(f\"Shape of y_test_reg: {y_test_reg.shape}\")\n",
        "\n",
        "# Instantiate StandardScaler\n",
        "scaler_reg = StandardScaler()\n",
        "\n",
        "# Fit on training data and transform training data\n",
        "X_train_scaled_reg = scaler_reg.fit_transform(X_train_reg)\n",
        "\n",
        "# Transform test data using the fitted scaler\n",
        "X_test_scaled_reg = scaler_reg.transform(X_test_reg)\n",
        "\n",
        "print(\"\\nFeatures scaled successfully using StandardScaler for regression.\")\n",
        "print(f\"Shape of X_train_scaled_reg: {X_train_scaled_reg.shape}\")\n",
        "print(f\"Shape of X_test_scaled_reg: {X_test_scaled_reg.shape}\")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train.csv loaded successfully from URL for regression task.\n",
            "\n",
            "Original features before preprocessing for regression:\n",
            "   Pclass   Age  SibSp  Parch     Sex Embarked\n",
            "0       3  22.0      1      0    male        S\n",
            "1       1  38.0      1      0  female        C\n",
            "2       3  26.0      0      0  female        S\n",
            "3       1  35.0      1      0  female        S\n",
            "4       3  35.0      0      0    male        S\n",
            "\n",
            "Target variable for regression:\n",
            "0     7.2500\n",
            "1    71.2833\n",
            "2     7.9250\n",
            "3    53.1000\n",
            "4     8.0500\n",
            "Name: Fare, dtype: float64\n",
            "\n",
            "Missing values in features after imputation for regression:\n",
            "Pclass      0\n",
            "Age         0\n",
            "SibSp       0\n",
            "Parch       0\n",
            "Sex         0\n",
            "Embarked    0\n",
            "dtype: int64\n",
            "Missing values in target after imputation for regression:\n",
            "0\n",
            "\n",
            "Features after one-hot encoding for regression:\n",
            "   Pclass   Age  SibSp  Parch  Sex_male  Embarked_Q  Embarked_S\n",
            "0       3  22.0      1      0         1           0           1\n",
            "1       1  38.0      1      0         0           0           0\n",
            "2       3  26.0      0      0         0           0           1\n",
            "3       1  35.0      1      0         0           0           1\n",
            "4       3  35.0      0      0         1           0           1\n",
            "\n",
            "Shape of X_train_reg: (712, 7)\n",
            "Shape of X_test_reg: (179, 7)\n",
            "Shape of y_train_reg: (712,)\n",
            "Shape of y_test_reg: (179,)\n",
            "\n",
            "Features scaled successfully using StandardScaler for regression.\n",
            "Shape of X_train_scaled_reg: (712, 7)\n",
            "Shape of X_test_scaled_reg: (179, 7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "04d09cd4",
        "outputId": "568f211a-f79c-4046-bbc2-5491fc1a7f27"
      },
      "source": [
        "from sklearn.svm import SVR\n",
        "\n",
        "# Instantiate and train the SVR with a linear kernel\n",
        "svr_linear = SVR(kernel='linear')\n",
        "svr_linear.fit(X_train_scaled_reg, y_train_reg)\n",
        "print(\"SVR with linear kernel trained successfully.\")\n",
        "\n",
        "# Instantiate and train the SVR with an RBF kernel\n",
        "svr_rbf = SVR(kernel='rbf')\n",
        "svr_rbf.fit(X_train_scaled_reg, y_train_reg)\n",
        "print(\"SVR with RBF kernel trained successfully.\")"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVR with linear kernel trained successfully.\n",
            "SVR with RBF kernel trained successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "85da782f",
        "outputId": "7c7c642c-848f-4075-fa76-a2afe6edb737"
      },
      "source": [
        "from sklearn.svm import SVR\n",
        "\n",
        "# Instantiate and train the SVR with a linear kernel\n",
        "svr_linear = SVR(kernel='linear')\n",
        "svr_linear.fit(X_train_scaled_reg, y_train_reg)\n",
        "print(\"SVR with linear kernel trained successfully.\")\n",
        "\n",
        "# Instantiate and train the SVR with an RBF kernel\n",
        "svr_rbf = SVR(kernel='rbf')\n",
        "svr_rbf.fit(X_train_scaled_reg, y_train_reg)\n",
        "print(\"SVR with RBF kernel trained successfully.\")"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVR with linear kernel trained successfully.\n",
            "SVR with RBF kernel trained successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ffc60919",
        "outputId": "8f7876d9-e9f9-4839-a48d-01e060c2b846"
      },
      "source": [
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "# --- Evaluate Linear Kernel SVR ---\n",
        "print(\"\\n--- Linear Kernel SVR Evaluation ---\")\n",
        "# Make predictions on the scaled test set\n",
        "y_pred_linear_reg = svr_linear.predict(X_test_scaled_reg)\n",
        "\n",
        "# Calculate MSE\n",
        "mse_linear = mean_squared_error(y_test_reg, y_pred_linear_reg)\n",
        "print(f\"MSE (Linear Kernel): {mse_linear:.4f}\")\n",
        "\n",
        "# Calculate RMSE\n",
        "rmse_linear = np.sqrt(mse_linear)\n",
        "print(f\"RMSE (Linear Kernel): {rmse_linear:.4f}\")\n",
        "\n",
        "# Calculate R^2 score\n",
        "r2_linear = r2_score(y_test_reg, y_pred_linear_reg)\n",
        "print(f\"R^2 Score (Linear Kernel): {r2_linear:.4f}\")\n",
        "\n",
        "# --- Evaluate RBF Kernel SVR ---\n",
        "print(\"\\n--- RBF Kernel SVR Evaluation ---\")\n",
        "# Make predictions on the scaled test set\n",
        "y_pred_rbf_reg = svr_rbf.predict(X_test_scaled_reg)\n",
        "\n",
        "# Calculate MSE\n",
        "mse_rbf = mean_squared_error(y_test_reg, y_pred_rbf_reg)\n",
        "print(f\"MSE (RBF Kernel): {mse_rbf:.4f}\")\n",
        "\n",
        "# Calculate RMSE\n",
        "rmse_rbf = np.sqrt(mse_rbf)\n",
        "print(f\"RMSE (RBF Kernel): {rmse_rbf:.4f}\")\n",
        "\n",
        "# Calculate R^2 score\n",
        "r2_rbf = r2_score(y_test_reg, y_pred_rbf_reg)\n",
        "print(f\"R^2 Score (RBF Kernel): {r2_rbf:.4f}\")"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Linear Kernel SVR Evaluation ---\n",
            "MSE (Linear Kernel): 992.0986\n",
            "RMSE (Linear Kernel): 31.4976\n",
            "R^2 Score (Linear Kernel): 0.3589\n",
            "\n",
            "--- RBF Kernel SVR Evaluation ---\n",
            "MSE (RBF Kernel): 1141.8061\n",
            "RMSE (RBF Kernel): 33.7906\n",
            "R^2 Score (RBF Kernel): 0.2621\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "529fc85b",
        "outputId": "bd27d73b-a159-4be5-8286-b4d3d270476d"
      },
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Instantiate a LinearRegression object\n",
        "linear_reg_model = LinearRegression()\n",
        "\n",
        "# Train the Linear Regression model using the scaled training data\n",
        "linear_reg_model.fit(X_train_scaled_reg, y_train_reg)\n",
        "\n",
        "print(\"Linear Regression model trained successfully.\")"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linear Regression model trained successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "08295a8b",
        "outputId": "e87097f8-6a34-46a2-d00a-1813462747af"
      },
      "source": [
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "# Make predictions on the scaled test set using the Linear Regression model\n",
        "y_pred_linear_reg_model = linear_reg_model.predict(X_test_scaled_reg)\n",
        "\n",
        "print(\"\\n--- Linear Regression Model Evaluation ---\")\n",
        "\n",
        "# Calculate MSE\n",
        "mse_linear_reg_model = mean_squared_error(y_test_reg, y_pred_linear_reg_model)\n",
        "print(f\"MSE (Linear Regression): {mse_linear_reg_model:.4f}\")\n",
        "\n",
        "# Calculate RMSE\n",
        "rmse_linear_reg_model = np.sqrt(mse_linear_reg_model)\n",
        "print(f\"RMSE (Linear Regression): {rmse_linear_reg_model:.4f}\")\n",
        "\n",
        "# Calculate R^2 score\n",
        "r2_linear_reg_model = r2_score(y_test_reg, y_pred_linear_reg_model)\n",
        "print(f\"R^2 Score (Linear Regression): {r2_linear_reg_model:.4f}\")"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Linear Regression Model Evaluation ---\n",
            "MSE (Linear Regression): 928.7293\n",
            "RMSE (Linear Regression): 30.4751\n",
            "R^2 Score (Linear Regression): 0.3998\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3b7509c4",
        "outputId": "11357ef7-9ce1-47c1-93ba-8493cf125775"
      },
      "source": [
        "print(\"\\n--- Model Performance Comparison ---\")\n",
        "\n",
        "print(f\"\\nLinear Kernel SVR:\")\n",
        "print(f\"  MSE: {mse_linear:.4f}\")\n",
        "print(f\"  RMSE: {rmse_linear:.4f}\")\n",
        "print(f\"  R^2 Score: {r2_linear:.4f}\")\n",
        "\n",
        "print(f\"\\nRBF Kernel SVR:\")\n",
        "print(f\"  MSE: {mse_rbf:.4f}\")\n",
        "print(f\"  RMSE: {rmse_rbf:.4f}\")\n",
        "print(f\"  R^2 Score: {r2_rbf:.4f}\")\n",
        "\n",
        "print(f\"\\nLinear Regression:\")\n",
        "print(f\"  MSE: {mse_linear_reg_model:.4f}\")\n",
        "print(f\"  RMSE: {rmse_linear_reg_model:.4f}\")\n",
        "print(f\"  R^2 Score: {r2_linear_reg_model:.4f}\")\n",
        "\n",
        "# Determine the best performing model based on R^2 score (higher is better)\n",
        "# and MSE/RMSE (lower is better)\n",
        "\n",
        "# Create a dictionary to hold R^2 scores for easier comparison\n",
        "r2_scores = {\n",
        "    'Linear Kernel SVR': r2_linear,\n",
        "    'RBF Kernel SVR': r2_rbf,\n",
        "    'Linear Regression': r2_linear_reg_model\n",
        "}\n",
        "\n",
        "best_model_r2 = max(r2_scores, key=r2_scores.get)\n",
        "\n",
        "print(f\"\\nBased on R^2 score, the '{best_model_r2}' model performed best with an R^2 score of {r2_scores[best_model_r2]:.4f}.\")\n",
        "\n",
        "# Also compare MSE/RMSE for consistency\n",
        "mse_scores = {\n",
        "    'Linear Kernel SVR': mse_linear,\n",
        "    'RBF Kernel SVR': mse_rbf,\n",
        "    'Linear Regression': mse_linear_reg_model\n",
        "}\n",
        "\n",
        "best_model_mse = min(mse_scores, key=mse_scores.get)\n",
        "print(f\"Based on MSE, the '{best_model_mse}' model performed best with an MSE of {mse_scores[best_model_mse]:.4f}.\")\n",
        "\n",
        "print(\"\\nJustification:\")\n",
        "print(\"The R^2 score indicates the proportion of the variance in the dependent variable that is predictable from the independent variables. A higher R^2 score implies a better fit of the model to the data. Conversely, MSE and RMSE measure the average squared difference and average difference between the predicted and actual values, respectively. Lower MSE and RMSE values indicate better model accuracy.\")\n",
        "print(f\"In this case, the '{best_model_r2}' model (which is also '{best_model_mse}' based on MSE) has the highest R^2 score and the lowest MSE/RMSE, indicating it is the most effective at explaining the variance in 'Fare' and making accurate predictions among the evaluated models.\")"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Model Performance Comparison ---\n",
            "\n",
            "Linear Kernel SVR:\n",
            "  MSE: 992.0986\n",
            "  RMSE: 31.4976\n",
            "  R^2 Score: 0.3589\n",
            "\n",
            "RBF Kernel SVR:\n",
            "  MSE: 1141.8061\n",
            "  RMSE: 33.7906\n",
            "  R^2 Score: 0.2621\n",
            "\n",
            "Linear Regression:\n",
            "  MSE: 928.7293\n",
            "  RMSE: 30.4751\n",
            "  R^2 Score: 0.3998\n",
            "\n",
            "Based on R^2 score, the 'Linear Regression' model performed best with an R^2 score of 0.3998.\n",
            "Based on MSE, the 'Linear Regression' model performed best with an MSE of 928.7293.\n",
            "\n",
            "Justification:\n",
            "The R^2 score indicates the proportion of the variance in the dependent variable that is predictable from the independent variables. A higher R^2 score implies a better fit of the model to the data. Conversely, MSE and RMSE measure the average squared difference and average difference between the predicted and actual values, respectively. Lower MSE and RMSE values indicate better model accuracy.\n",
            "In this case, the 'Linear Regression' model (which is also 'Linear Regression' based on MSE) has the highest R^2 score and the lowest MSE/RMSE, indicating it is the most effective at explaining the variance in 'Fare' and making accurate predictions among the evaluated models.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Tasks:5\n",
        "1. Load dataset and encode categorical variables.\n",
        "2. Select features\n",
        "3. Train SVR model with different kernels:\n",
        "RBF\n",
        "Polynomial\n",
        "4. Evaluate each model using:\n",
        "MAE\n",
        "RMSE\n",
        "R Score\n",
        "5. Conclude which kernel is best for predicting insurance cost.\n"
      ],
      "metadata": {
        "id": "1gSs29jfco7G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3MZuCgYOd7a9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dd4d316b",
        "outputId": "5da69d5c-117e-4156-929d-532de52d691f"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import requests\n",
        "from io import StringIO\n",
        "\n",
        "# URL for the insurance.csv file\n",
        "url_insurance = \"https://raw.githubusercontent.com/stedy/Machine-Learning-with-R-datasets/master/insurance.csv\"\n",
        "\n",
        "try:\n",
        "    # Attempt to download the file directly\n",
        "    response = requests.get(url_insurance)\n",
        "    response.raise_for_status() # Raise an exception for HTTP errors (4xx or 5xx)\n",
        "\n",
        "    # Load the insurance.csv file from the downloaded content\n",
        "    df_insurance = pd.read_csv(StringIO(response.text))\n",
        "    print(\"insurance.csv loaded successfully from URL.\")\n",
        "\n",
        "except requests.exceptions.RequestException as e:\n",
        "    print(f\"Error downloading or loading file from URL: {e}\")\n",
        "    # Fallback to local file if URL fails\n",
        "    try:\n",
        "        df_insurance = pd.read_csv('insurance.csv')\n",
        "        print(\"insurance.csv loaded successfully from local file (fallback).\")\n",
        "    except FileNotFoundError:\n",
        "        print(\"insurance.csv not found locally either. Please ensure the file is in the correct directory or the URL is valid.\")\n",
        "        df_insurance = pd.DataFrame() # Create an empty DataFrame to prevent further errors\n",
        "\n",
        "# Display the first 5 rows of the DataFrame\n",
        "print(\"\\nFirst 5 rows of the insurance DataFrame:\")\n",
        "print(df_insurance.head())\n",
        "\n",
        "# Display column names and their data types\n",
        "print(\"\\nInsurance DataFrame Info:\")\n",
        "df_insurance.info()\n",
        "\n",
        "# Identify target and features\n",
        "target_insurance = 'charges'\n",
        "y_insurance = df_insurance[target_insurance].copy()\n",
        "X_insurance = df_insurance.drop(columns=[target_insurance]).copy()\n",
        "\n",
        "print(f\"\\nTarget variable identified: {target_insurance}\")\n",
        "print(f\"Initial features for insurance data: {list(X_insurance.columns)}\")\n",
        "\n",
        "# Handle missing values\n",
        "# Numerical columns imputation with mean\n",
        "for col in X_insurance.select_dtypes(include=np.number).columns:\n",
        "    if X_insurance[col].isnull().sum() > 0:\n",
        "        X_insurance[col].fillna(X_insurance[col].mean(), inplace=True)\n",
        "\n",
        "# Categorical columns imputation with mode\n",
        "for col in X_insurance.select_dtypes(include='object').columns:\n",
        "    if X_insurance[col].isnull().sum() > 0:\n",
        "        X_insurance[col].fillna(X_insurance[col].mode()[0], inplace=True)\n",
        "\n",
        "# Handle missing values in target variable if any (unlikely for charges, but good practice)\n",
        "if y_insurance.isnull().sum() > 0:\n",
        "    y_insurance.fillna(y_insurance.mean(), inplace=True)\n",
        "\n",
        "print(\"\\nMissing values in features after imputation:\")\n",
        "print(X_insurance.isnull().sum())\n",
        "print(\"Missing values in target after imputation:\")\n",
        "print(y_insurance.isnull().sum())\n",
        "\n",
        "# Identify categorical features for one-hot encoding\n",
        "categorical_features_insurance = X_insurance.select_dtypes(include='object').columns.tolist()\n",
        "\n",
        "# Apply one-hot encoding\n",
        "X_insurance = pd.get_dummies(X_insurance, columns=categorical_features_insurance, drop_first=True, dtype=int)\n",
        "\n",
        "print(\"\\nFeatures after one-hot encoding for insurance data:\")\n",
        "print(X_insurance.head())\n",
        "\n",
        "# Split the preprocessed data into training and testing sets\n",
        "X_train_insurance, X_test_insurance, y_train_insurance, y_test_insurance = train_test_split(X_insurance, y_insurance, test_size=0.2, random_state=42)\n",
        "\n",
        "print(f\"\\nShape of X_train_insurance: {X_train_insurance.shape}\")\n",
        "print(f\"Shape of X_test_insurance: {X_test_insurance.shape}\")\n",
        "print(f\"Shape of y_train_insurance: {y_train_insurance.shape}\")\n",
        "print(f\"Shape of y_test_insurance: {y_test_insurance.shape}\")\n",
        "\n",
        "# Instantiate and apply StandardScaler\n",
        "scaler_insurance = StandardScaler()\n",
        "X_train_scaled_insurance = scaler_insurance.fit_transform(X_train_insurance)\n",
        "X_test_scaled_insurance = scaler_insurance.transform(X_test_insurance)\n",
        "\n",
        "print(\"\\nFeatures scaled successfully using StandardScaler for insurance data.\")\n",
        "print(f\"Shape of X_train_scaled_insurance: {X_train_scaled_insurance.shape}\")\n",
        "print(f\"Shape of X_test_scaled_insurance: {X_test_scaled_insurance.shape}\")"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "insurance.csv loaded successfully from URL.\n",
            "\n",
            "First 5 rows of the insurance DataFrame:\n",
            "   age     sex     bmi  children smoker     region      charges\n",
            "0   19  female  27.900         0    yes  southwest  16884.92400\n",
            "1   18    male  33.770         1     no  southeast   1725.55230\n",
            "2   28    male  33.000         3     no  southeast   4449.46200\n",
            "3   33    male  22.705         0     no  northwest  21984.47061\n",
            "4   32    male  28.880         0     no  northwest   3866.85520\n",
            "\n",
            "Insurance DataFrame Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1338 entries, 0 to 1337\n",
            "Data columns (total 7 columns):\n",
            " #   Column    Non-Null Count  Dtype  \n",
            "---  ------    --------------  -----  \n",
            " 0   age       1338 non-null   int64  \n",
            " 1   sex       1338 non-null   object \n",
            " 2   bmi       1338 non-null   float64\n",
            " 3   children  1338 non-null   int64  \n",
            " 4   smoker    1338 non-null   object \n",
            " 5   region    1338 non-null   object \n",
            " 6   charges   1338 non-null   float64\n",
            "dtypes: float64(2), int64(2), object(3)\n",
            "memory usage: 73.3+ KB\n",
            "\n",
            "Target variable identified: charges\n",
            "Initial features for insurance data: ['age', 'sex', 'bmi', 'children', 'smoker', 'region']\n",
            "\n",
            "Missing values in features after imputation:\n",
            "age         0\n",
            "sex         0\n",
            "bmi         0\n",
            "children    0\n",
            "smoker      0\n",
            "region      0\n",
            "dtype: int64\n",
            "Missing values in target after imputation:\n",
            "0\n",
            "\n",
            "Features after one-hot encoding for insurance data:\n",
            "   age     bmi  children  sex_male  smoker_yes  region_northwest  \\\n",
            "0   19  27.900         0         0           1                 0   \n",
            "1   18  33.770         1         1           0                 0   \n",
            "2   28  33.000         3         1           0                 0   \n",
            "3   33  22.705         0         1           0                 1   \n",
            "4   32  28.880         0         1           0                 1   \n",
            "\n",
            "   region_southeast  region_southwest  \n",
            "0                 0                 1  \n",
            "1                 1                 0  \n",
            "2                 1                 0  \n",
            "3                 0                 0  \n",
            "4                 0                 0  \n",
            "\n",
            "Shape of X_train_insurance: (1070, 8)\n",
            "Shape of X_test_insurance: (268, 8)\n",
            "Shape of y_train_insurance: (1070,)\n",
            "Shape of y_test_insurance: (268,)\n",
            "\n",
            "Features scaled successfully using StandardScaler for insurance data.\n",
            "Shape of X_train_scaled_insurance: (1070, 8)\n",
            "Shape of X_test_scaled_insurance: (268, 8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1d4666e",
        "outputId": "9ad9e0e1-631a-45f5-bc1f-4abd5da755e3"
      },
      "source": [
        "from sklearn.svm import SVR\n",
        "\n",
        "# Instantiate SVR with RBF kernel\n",
        "svr_rbf_insurance = SVR(kernel='rbf')\n",
        "\n",
        "# Fit the model to the scaled training data\n",
        "svr_rbf_insurance.fit(X_train_scaled_insurance, y_train_insurance)\n",
        "\n",
        "print(\"SVR model with RBF kernel trained successfully for insurance data.\")"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVR model with RBF kernel trained successfully for insurance data.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5097b653",
        "outputId": "642a1ee9-efd0-4075-c732-d9ec07ae6063"
      },
      "source": [
        "from sklearn.svm import SVR\n",
        "\n",
        "# Instantiate SVR with Polynomial kernel\n",
        "# You might want to experiment with 'degree' for the polynomial kernel\n",
        "svr_poly_insurance = SVR(kernel='poly', degree=3) # Default degree is 3, but can be specified\n",
        "\n",
        "# Fit the model to the scaled training data\n",
        "svr_poly_insurance.fit(X_train_scaled_insurance, y_train_insurance)\n",
        "\n",
        "print(\"SVR model with Polynomial kernel trained successfully for insurance data.\")"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVR model with Polynomial kernel trained successfully for insurance data.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "84379184",
        "outputId": "9e6192bf-f9f4-4173-8e86-6960cd31d563"
      },
      "source": [
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "# --- Evaluate RBF Kernel SVR ---\n",
        "print(\"\\n--- RBF Kernel SVR Evaluation ---\")\n",
        "# Make predictions on the scaled test set\n",
        "y_pred_rbf_insurance = svr_rbf_insurance.predict(X_test_scaled_insurance)\n",
        "\n",
        "# Calculate MAE\n",
        "mae_rbf_insurance = mean_absolute_error(y_test_insurance, y_pred_rbf_insurance)\n",
        "print(f\"MAE (RBF Kernel): {mae_rbf_insurance:.4f}\")\n",
        "\n",
        "# Calculate MSE and RMSE\n",
        "mse_rbf_insurance = mean_squared_error(y_test_insurance, y_pred_rbf_insurance)\n",
        "rmse_rbf_insurance = np.sqrt(mse_rbf_insurance)\n",
        "print(f\"RMSE (RBF Kernel): {rmse_rbf_insurance:.4f}\")\n",
        "\n",
        "# Calculate R^2 score\n",
        "r2_rbf_insurance = r2_score(y_test_insurance, y_pred_rbf_insurance)\n",
        "print(f\"R^2 Score (RBF Kernel): {r2_rbf_insurance:.4f}\")\n",
        "\n",
        "# --- Evaluate Polynomial Kernel SVR ---\n",
        "print(\"\\n--- Polynomial Kernel SVR Evaluation ---\")\n",
        "# Make predictions on the scaled test set\n",
        "y_pred_poly_insurance = svr_poly_insurance.predict(X_test_scaled_insurance)\n",
        "\n",
        "# Calculate MAE\n",
        "mae_poly_insurance = mean_absolute_error(y_test_insurance, y_pred_poly_insurance)\n",
        "print(f\"MAE (Polynomial Kernel): {mae_poly_insurance:.4f}\")\n",
        "\n",
        "# Calculate MSE and RMSE\n",
        "mse_poly_insurance = mean_squared_error(y_test_insurance, y_pred_poly_insurance)\n",
        "rmse_poly_insurance = np.sqrt(mse_poly_insurance)\n",
        "print(f\"RMSE (Polynomial Kernel): {rmse_poly_insurance:.4f}\")\n",
        "\n",
        "# Calculate R^2 score\n",
        "r2_poly_insurance = r2_score(y_test_insurance, y_pred_poly_insurance)\n",
        "print(f\"R^2 Score (Polynomial Kernel): {r2_poly_insurance:.4f}\")"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- RBF Kernel SVR Evaluation ---\n",
            "MAE (RBF Kernel): 8612.4084\n",
            "RMSE (RBF Kernel): 12889.0963\n",
            "R^2 Score (RBF Kernel): -0.0701\n",
            "\n",
            "--- Polynomial Kernel SVR Evaluation ---\n",
            "MAE (Polynomial Kernel): 8607.8014\n",
            "RMSE (Polynomial Kernel): 12872.9614\n",
            "R^2 Score (Polynomial Kernel): -0.0674\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "878ee733",
        "outputId": "60123cea-23ba-471d-b3c2-af79ea6b145b"
      },
      "source": [
        "print(\"\\n--- SVR Kernel Performance Comparison for Insurance Data ---\")\n",
        "\n",
        "print(f\"\\nRBF Kernel SVR:\")\n",
        "print(f\"  MAE: {mae_rbf_insurance:.4f}\")\n",
        "print(f\"  RMSE: {rmse_rbf_insurance:.4f}\")\n",
        "print(f\"  R^2 Score: {r2_rbf_insurance:.4f}\")\n",
        "\n",
        "print(f\"\\nPolynomial Kernel SVR:\")\n",
        "print(f\"  MAE: {mae_poly_insurance:.4f}\")\n",
        "print(f\"  RMSE: {rmse_poly_insurance:.4f}\")\n",
        "print(f\"  R^2 Score: {r2_poly_insurance:.4f}\")\n",
        "\n",
        "# Compare performance based on R^2 score (higher is better) and MAE/RMSE (lower is better)\n",
        "if r2_rbf_insurance > r2_poly_insurance:\n",
        "    best_svr_kernel = 'RBF'\n",
        "    best_mae = mae_rbf_insurance\n",
        "    best_rmse = rmse_rbf_insurance\n",
        "    best_r2 = r2_rbf_insurance\n",
        "    second_svr_kernel = 'Polynomial'\n",
        "    second_mae = mae_poly_insurance\n",
        "    second_rmse = rmse_poly_insurance\n",
        "    second_r2 = r2_poly_insurance\n",
        "else:\n",
        "    best_svr_kernel = 'Polynomial'\n",
        "    best_mae = mae_poly_insurance\n",
        "    best_rmse = rmse_poly_insurance\n",
        "    best_r2 = r2_poly_insurance\n",
        "    second_svr_kernel = 'RBF'\n",
        "    second_mae = mae_rbf_insurance\n",
        "    second_rmse = rmse_rbf_insurance\n",
        "    second_r2 = r2_rbf_insurance\n",
        "\n",
        "print(f\"\\nBased on R^2 score, MAE, and RMSE, the '{best_svr_kernel}' kernel performed slightly better.\")\n",
        "\n",
        "print(\"\\n--- Justification ---\")\n",
        "print(f\"Both SVR models, using RBF and Polynomial kernels, performed poorly on this dataset, as indicated by their negative R^2 scores. A negative R^2 score means that the model performs worse than simply predicting the mean of the target variable for all instances. This suggests that SVR with default hyperparameters and these kernels might not be well-suited for this particular regression task or that extensive hyperparameter tuning (e.g., for C, epsilon, and gamma/degree) is required.\")\n",
        "print(f\"\\nComparing the two, the {best_svr_kernel} kernel shows slightly better performance with an R^2 score of {best_r2:.4f} (closer to zero, indicating marginally less poor fit than the other). It also has a slightly lower MAE ({best_mae:.4f}) and RMSE ({best_rmse:.4f}) compared to the {second_svr_kernel} kernel's MAE of {second_mae:.4f} and RMSE of {second_rmse:.4f}. While the difference is very small and both models are ineffective, the {best_svr_kernel} kernel marginally outperforms the {second_svr_kernel} kernel for predicting insurance costs in this evaluation.\")\n"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- SVR Kernel Performance Comparison for Insurance Data ---\n",
            "\n",
            "RBF Kernel SVR:\n",
            "  MAE: 8612.4084\n",
            "  RMSE: 12889.0963\n",
            "  R^2 Score: -0.0701\n",
            "\n",
            "Polynomial Kernel SVR:\n",
            "  MAE: 8607.8014\n",
            "  RMSE: 12872.9614\n",
            "  R^2 Score: -0.0674\n",
            "\n",
            "Based on R^2 score, MAE, and RMSE, the 'Polynomial' kernel performed slightly better.\n",
            "\n",
            "--- Justification ---\n",
            "Both SVR models, using RBF and Polynomial kernels, performed poorly on this dataset, as indicated by their negative R^2 scores. A negative R^2 score means that the model performs worse than simply predicting the mean of the target variable for all instances. This suggests that SVR with default hyperparameters and these kernels might not be well-suited for this particular regression task or that extensive hyperparameter tuning (e.g., for C, epsilon, and gamma/degree) is required.\n",
            "\n",
            "Comparing the two, the Polynomial kernel shows slightly better performance with an R^2 score of -0.0674 (closer to zero, indicating marginally less poor fit than the other). It also has a slightly lower MAE (8607.8014) and RMSE (12872.9614) compared to the RBF kernel's MAE of 8612.4084 and RMSE of 12889.0963. While the difference is very small and both models are ineffective, the Polynomial kernel marginally outperforms the RBF kernel for predicting insurance costs in this evaluation.\n"
          ]
        }
      ]
    }
  ]
}